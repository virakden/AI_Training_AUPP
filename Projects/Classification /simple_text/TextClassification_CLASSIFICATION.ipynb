{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1XpLftPi4A"
      },
      "source": [
        "# Natural Language Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsGqx_ai_N8F"
      },
      "outputs": [],
      "source": [
        "# Import Tensorflow 2.0\n",
        "# !pip install tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from urllib.request import urlopen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKjrdUtX_N8J"
      },
      "source": [
        "## 1.0 Traffic Accident  Dataset\n",
        "\n",
        "https://medium.com/@phylypo/text-classification-with-scikit-learn-on-khmer-documents-1a395317d195\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2dQsHI3_N8K"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#data = urllib2.urlopen(target_url) # it's a file like object and works just like a file\n",
        "# open a file, where you stored the pickled data\n",
        "file = urlopen('https://raw.githubusercontent.com/phylypo/khmer-text-data/master/classifications/accident_docs.pkl')\n",
        "\n",
        "# dump information to that file\n",
        "data = pickle.load(file)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "id": "HR_8FDz96QUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "6tM7abLa6Ud_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data['cat']!='accident','cat']= 0\n",
        "data.loc[data['cat']=='accident','cat']= 1"
      ],
      "metadata": {
        "id": "rn9jPWZ89Cuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cat'] = data['cat'].astype(int)"
      ],
      "metadata": {
        "id": "pN5jg0Qo9UUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6hd3Nt1_N8q"
      },
      "source": [
        "## 2.0 Khmer Text Classification\n",
        "\n",
        "**Objective** is to\n",
        "\n",
        "1. vectorize the Khmer texts.\n",
        "\n",
        "2. train a text classifier model.\n",
        "\n",
        "3. evaluate the model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rphS2rMIymyZ"
      },
      "source": [
        "### Khmer Text Vectorizer\n",
        "\n",
        "Using sklearn vectorizers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMZsbjAkDKpU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def tokenizer(str):\n",
        "    return str.split();\n",
        "\n",
        "\n",
        "## TO DO: Vectorize the texts using the above tokenizer\n",
        "\n",
        "## YOUR CODES:\n",
        "\n",
        "\n",
        "## END OF YOUR CODES\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "\n",
        "\n",
        "### Dataset Spliting - Train and Test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TO DO: Split the vectorized dataset and its label into train and test sets\n",
        "\n",
        "## YOUR CODES:\n",
        "\n",
        "\n",
        "## END OF YOUR CODES\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9mVK2m8E0m12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "### Train and evaluate the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFMbIqIvQ2X0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train_model(classifier, trains, t_labels, valids, v_labels):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(trains, t_labels)\n",
        "\n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(valids)\n",
        "\n",
        "    return accuracy_score(predictions, v_labels)\n",
        "\n",
        "\n",
        "## TO DO: Model training and evaluation\n",
        "\n",
        "## YOUR CODES:\n",
        "\n",
        "\n",
        "## END OF YOUR CODES\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baIw9bDf8v6Z"
      },
      "source": [
        "## 3.0 Repeat the above steps for multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vec9qcJs-9W5"
      },
      "outputs": [],
      "source": [
        "## TO DO: Repeat the above steps for multi-class classification\n",
        "\n",
        "## YOUR CODES:\n",
        "\n",
        "## END OF YOUR CODES"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.0 Model Deployment on Gradio"
      ],
      "metadata": {
        "id": "1wHhZoaD1v3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TO DO: Model deployment on Gradio\n",
        "\n",
        "## YOUR CODES:\n",
        "\n",
        "\n",
        "## END OF YOUR CODES"
      ],
      "metadata": {
        "id": "nnPk7GM210PM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}